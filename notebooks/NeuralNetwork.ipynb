{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from PIL import Image\n",
    "import scipy\n",
    "\n",
    "# # Tensorflow and Keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Xception because other model not working\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "#os.chdir('../')\n",
    "from src import image_preprocess as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with histology data\n",
    "for each 40X, 100X, 200X, 400X, have 644 items for benign and 1300 for malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment our benign data since we only have ~650 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is already fairly uniform. No major changes for augmentation\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='constant',\n",
    "                            cval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maureen/Documents/Galvanize/Capstone1/Capstone3/Cancer_Prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(460, 700, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "img = Image.open('data/Histology/100X/benign/SOB_B_A-14-22549AB-100-001.png')\n",
    "x = img_to_array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir('data/Histology/100X/benign')]\n",
    "\n",
    "for f in files:\n",
    "    img = Image.open(os.path.join('data/Histology/100X/benign',f))\n",
    "    x = ip.reshape_image(img)\n",
    "    ip.create_new_images(x)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/maureen/Documents/Galvanize/Capstone1/Capstone3/Cancer_Prediction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken frm cnn lectures \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=8, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(460, 700, 3),\n",
    "                 kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5),\n",
    "                 strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(10,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train[..., None], y_train,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          batch_size=50,\n",
    "          validation_data=(X_test[..., None], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = model.layers[0].get_weights()[0]\n",
    "weights1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try new model because previous isn't working\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_transfer_model(input_size, n_categories, weights = 'imagenet'):\n",
    "        # note that the \"top\" is not included in the weights below\n",
    "        base_model = Xception(weights=weights,\n",
    "                          include_top=False,\n",
    "                          input_shape=input_size)\n",
    "        \n",
    "        model = base_model.output\n",
    "        model = GlobalAveragePooling2D()(model)\n",
    "        predictions = Dense(n_categories, activation='softmax')(model)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_transfer_model((460,700,3),2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_properties(model, indices = 0):\n",
    "    for i, layer in enumerate(model.layers[indices:]):\n",
    "        print(i+indices, layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_5 True\n",
      "1 block1_conv1 True\n",
      "2 block1_conv1_bn True\n",
      "3 block1_conv1_act True\n",
      "4 block1_conv2 True\n",
      "5 block1_conv2_bn True\n",
      "6 block1_conv2_act True\n",
      "7 block2_sepconv1 True\n",
      "8 block2_sepconv1_bn True\n",
      "9 block2_sepconv2_act True\n",
      "10 block2_sepconv2 True\n",
      "11 block2_sepconv2_bn True\n",
      "12 conv2d_16 True\n",
      "13 block2_pool True\n",
      "14 batch_normalization_16 True\n",
      "15 add_48 True\n",
      "16 block3_sepconv1_act True\n",
      "17 block3_sepconv1 True\n",
      "18 block3_sepconv1_bn True\n",
      "19 block3_sepconv2_act True\n",
      "20 block3_sepconv2 True\n",
      "21 block3_sepconv2_bn True\n",
      "22 conv2d_17 True\n",
      "23 block3_pool True\n",
      "24 batch_normalization_17 True\n",
      "25 add_49 True\n",
      "26 block4_sepconv1_act True\n",
      "27 block4_sepconv1 True\n",
      "28 block4_sepconv1_bn True\n",
      "29 block4_sepconv2_act True\n",
      "30 block4_sepconv2 True\n",
      "31 block4_sepconv2_bn True\n",
      "32 conv2d_18 True\n",
      "33 block4_pool True\n",
      "34 batch_normalization_18 True\n",
      "35 add_50 True\n",
      "36 block5_sepconv1_act True\n",
      "37 block5_sepconv1 True\n",
      "38 block5_sepconv1_bn True\n",
      "39 block5_sepconv2_act True\n",
      "40 block5_sepconv2 True\n",
      "41 block5_sepconv2_bn True\n",
      "42 block5_sepconv3_act True\n",
      "43 block5_sepconv3 True\n",
      "44 block5_sepconv3_bn True\n",
      "45 add_51 True\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_52 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_53 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_54 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_55 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_56 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_57 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_58 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_19 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_19 True\n",
      "125 add_59 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "132 global_average_pooling2d_4 True\n",
      "133 dense_2 True\n"
     ]
    }
   ],
   "source": [
    "print_model_properties(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_trainable_layers(model, trainable_index):\n",
    "    for layer in model.layers[:trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[trainable_index:]:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 block14_sepconv2_bn False\n",
      "131 block14_sepconv2_act False\n",
      "132 global_average_pooling2d_4 True\n",
      "133 dense_2 True\n"
     ]
    }
   ],
   "source": [
    "_ = change_trainable_layers(model, 132)\n",
    "print_model_properties(model, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train[..., None], y_train,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          batch_size=50,\n",
    "          validation_data=(X_test[..., None], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try fast AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/Histology/100X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Go through folder, resize anything larger than 500 pix\n",
    "for folder in ['benign', 'malignant']:\n",
    "    print(folder)\n",
    "    verify_images(path/folder, delete=True, max_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Mammograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is already fairly uniform. No major changes for augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=5,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='constant',\n",
    "                            cval=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
